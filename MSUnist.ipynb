{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1 align = \"center\"> MSU-NIST </h1>\n",
        "\n",
        "## CS:3210 Machine Learning Final Project\n",
        "### Professor: Feng Jiang \n",
        "\n",
        "\n",
        "#### Team Members:\n",
        "* **Ling Thang**\n",
        "* **Joaquin Trujillo**\n",
        "\n",
        "#### Project Description:\n",
        "For our Final project we have decided to work on the classic digit recognition problem. Taking a spin on the classic MNSIT dataset we have decided to collect our own dataset from study around the Auraria campus housing the three schools MSU Denver, CU Denver, and CCD. We decided to take this approach because we believe that as machine learning students it is not only important to understand not just the application of machine learning but also the data collection, cleaning, and preprocessing that goes into it. We believe that this will give us a better understanding of the process and the challenges that come with it as well as the importance of data quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Third-party library imports\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Naigate to the folder and create classes for Digit Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
          ]
        }
      ],
      "source": [
        "data_dir = 'Data'\n",
        "# classes but only the directories\n",
        "files = os.listdir(data_dir)\n",
        "classes = [f for f in files if os.path.isdir(os.path.join(data_dir, f))]\n",
        "\n",
        "print(sorted(classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing the data \n",
        "\n",
        "## create two arrays X and y\n",
        "\n",
        "## Loop through the "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 100\n",
            "8: 100\n",
            "1: 100\n",
            "5: 100\n",
            "9: 100\n",
            "2: 100\n",
            "7: 100\n",
            "4: 100\n",
            "3: 100\n",
            "6: 100\n",
            "(1000, 28, 28, 4)\n"
          ]
        }
      ],
      "source": [
        "# Create empty np arrarys to store the images and labels\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "# Loop through the classes\n",
        "for i, c in enumerate(classes):\n",
        "    files = os.listdir(os.path.join(data_dir, c))\n",
        "    files = [f for f in files if f.endswith('.png')]\n",
        "    \n",
        "    # print the number of files in each class\n",
        "    print(f'{c}: {len(files)}')\n",
        "\n",
        "    # Loop through the images\n",
        "    for f in files:\n",
        "        img = Image.open(os.path.join(data_dir, c, f))\n",
        "        img = img.resize((28, 28))\n",
        "        img = np.array(img)\n",
        "        img = img / 255\n",
        "        img = img.astype(np.float32)\n",
        "        X.append(img)\n",
        "        y.append(i)\n",
        "\n",
        "# Convert lists to arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 28, 28, 4)\n",
            "(1000,)\n",
            "X_train shape: (800, 28, 28, 4)\n",
            "(800, 10)\n"
          ]
        }
      ],
      "source": [
        "# print the shape of the arrays\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the labels to one-hot encoding\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Save the data\n",
        "np.save('X_train.npy', X_train)\n",
        "np.save('X_test.npy', X_test)\n",
        "np.save('y_train.npy', y_train)\n",
        "np.save('y_test.npy', y_test)\n",
        "np.save('classes.npy', classes)\n",
        "\n",
        "#print('Data saved')\n",
        "print('X_train shape:', X_train.shape)\n",
        "print (y_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded\n",
            "(800, 28, 28, 4)\n",
            "(200, 28, 28, 4)\n",
            "(800, 10)\n",
            "(200, 10)\n",
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
          ]
        }
      ],
      "source": [
        "# Load the data\n",
        "X_train = np.load('X_train.npy')\n",
        "X_test = np.load('X_test.npy')\n",
        "y_train = np.load('y_train.npy')\n",
        "y_test = np.load('y_test.npy')\n",
        "classes = np.load('classes.npy')\n",
        "\n",
        "print('Data loaded')\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(sorted(classes))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# print a random sample images\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in range(10):\n",
        "    idx = np.random.randint(0, X_train.shape[0])\n",
        "    axes[i].imshow(X_train[idx])\n",
        "    axes[i].set_title(classes[np.argmax(y_train[idx])])\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of augmented dataset: (4000, 28, 28, 4)\n",
            "Shape of augmented labels: (4000, 10)\n"
          ]
        }
      ],
      "source": [
        "# data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "      rotation_range=10,  \n",
        "        zoom_range = 0.10,  \n",
        "        width_shift_range=0.1, \n",
        "        height_shift_range=0.1)\n",
        "\n",
        "augmented_X = []\n",
        "augmented_y = []\n",
        "\n",
        "# Generate augmented data for each sample in the dataset\n",
        "for i in range(len(X_train)):\n",
        "    X_train_example = X_train[i].reshape((1, 28, 28, 4))\n",
        "    y_train_example = y_train[i].reshape((1, 10))\n",
        "    num_augmented_samples = 5  # You can adjust the number of augmented samples per original sample\n",
        "    for _ in range(num_augmented_samples):\n",
        "        X_train_augmented, y_train_augmented = datagen.flow(X_train_example, y_train_example).__next__()\n",
        "        # Reshape augmented data to remove extra dizmension\n",
        "        X_train_augmented = X_train_augmented.squeeze(axis=0)\n",
        "        y_train_augmented = y_train_augmented.squeeze(axis=0)\n",
        "        augmented_X.append(X_train_augmented)\n",
        "        augmented_y.append(y_train_augmented)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "augmented_X = np.array(augmented_X)\n",
        "augmented_y = np.array(augmented_y)\n",
        "\n",
        "# Print the shape of the augmented dataset\n",
        "print(\"Shape of augmented dataset:\", augmented_X.shape)\n",
        "print(\"Shape of augmented labels:\", augmented_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/powoly/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), padding=\"same\", activation='relu', input_shape=(28, 28, 4)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), padding=\"same\", activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), padding=\"same\", activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "def intialize_model_train(model,epoch, batch_size):\n",
        "\tprint(\"******* training network *******\")\n",
        "# Compile the model with Adam optimizer\n",
        "\tadam_optimizer = Adam(learning_rate=0.001)  # You can adjust the learning rate as needed\n",
        "\tmodel.compile(loss=\"categorical_crossentropy\", optimizer=adam_optimizer, metrics=[\"accuracy\"])\n",
        "\t# go through the data 5 times with 128 batch sizes\n",
        "\tH = model.fit(augmented_X,augmented_y, validation_data=(X_test, y_test),\n",
        "\t\tepochs=epoch, batch_size=batch_size)\n",
        "\n",
        "\t# evaluate the network\n",
        "\tprint(\"******* evaluating network *******\")\n",
        "\tpredictions = model.predict(X_test, batch_size=batch_size)\n",
        "\tprint(classification_report(y_test.argmax(axis=1),\n",
        "\t\tpredictions.argmax(axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "******* training network *******\n",
            "Epoch 1/9\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.1013 - loss: 2.3179 - val_accuracy: 0.0650 - val_loss: 2.3146\n",
            "Epoch 2/9\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.1022 - loss: 2.3008 - val_accuracy: 0.0650 - val_loss: 2.3152\n",
            "Epoch 3/9\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.1177 - loss: 2.2849 - val_accuracy: 0.2850 - val_loss: 1.9306\n",
            "Epoch 4/9\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.2943 - loss: 1.9643 - val_accuracy: 0.7000 - val_loss: 1.0920\n",
            "Epoch 5/9\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4951 - loss: 1.4384 - val_accuracy: 0.7900 - val_loss: 0.7162\n",
            "Epoch 6/9\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6327 - loss: 1.0709 - val_accuracy: 0.8550 - val_loss: 0.4988\n",
            "Epoch 7/9\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7216 - loss: 0.8302 - val_accuracy: 0.8650 - val_loss: 0.3572\n",
            "Epoch 8/9\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7736 - loss: 0.6568 - val_accuracy: 0.8850 - val_loss: 0.3101\n",
            "Epoch 9/9\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8177 - loss: 0.5556 - val_accuracy: 0.9000 - val_loss: 0.2983\n",
            "******* evaluating network *******\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79348a969f30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79348a969f30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/stepWARNING:tensorflow:5 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79348a969f30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79348a969f30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95        20\n",
            "           1       0.83      0.77      0.80        13\n",
            "           2       0.96      1.00      0.98        27\n",
            "           3       0.87      0.62      0.72        21\n",
            "           4       0.93      0.93      0.93        15\n",
            "           5       0.91      0.91      0.91        22\n",
            "           6       0.92      0.96      0.94        25\n",
            "           7       0.93      1.00      0.96        13\n",
            "           8       0.75      0.91      0.82        23\n",
            "           9       0.95      0.90      0.93        21\n",
            "\n",
            "    accuracy                           0.90       200\n",
            "   macro avg       0.90      0.90      0.90       200\n",
            "weighted avg       0.90      0.90      0.90       200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "intialize_model_train(model,9,55)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "def Save_Model(model):\n",
        "    #os.chdir(\"SavedModels\")\n",
        "    model.save(\"NN.h5\")\n",
        "\n",
        "Save_Model(model)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
